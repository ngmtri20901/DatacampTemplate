{"cells":[{"source":"# Anonymize Sensitive Data\nProtecting sensitive information of individuals such as customers and employees is essential to any business. This template provides some techniques to introduce anonymity while still preserving data utility. It covers suppression, masking, and generalization.\n\nYou only need to have a dataset with columns that you want to anonymize to use this template. The first cell imports packages to manipulate and explore the data. It also imports the example data.\n\n_Note: This template's placeholder dataset uses a fake HR dataset containing information about fictional employees._","metadata":{},"id":"special-express","cell_type":"markdown"},{"source":"# Load packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style(\"darkgrid\")\n\n# Read in your data\ndf = pd.read_csv(\"data/employee.csv\")\n\n# Preview the data\ndf","metadata":{"scrolled":false},"id":"changing-peace","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Attribute Suppression\nOne of the first things you may want to do with new data is to perform attribute suppression: removing columns that are not useful to your analysis. Here, the template drops three columns that contain sensitive and personal information that may not be relevant to future analyses.\n\n_Note: The cells in this template are designed to be run once, as they drop the original columns to leave you with a transformed dataset. If you want to rerun them, you can always load the original data again from the first cell._","metadata":{},"id":"sized-macedonia","cell_type":"markdown"},{"source":"# Specify columns to drop from the dataset\ncolumns_to_drop = [\"Name\", \"EmployeeNumber\", \"Gender\"]\n\n# Drop the columns\ndf.drop(columns_to_drop, axis=\"columns\", inplace=True)\n\n# Preview the resulting DataFrame\ndf","metadata":{},"id":"massive-karen","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Record Suppression\nAlternatively, there may be cases where you want to perform record suppression: removing rows that are either not relevant to your analysis or have a risk of identification.\n\nIn this example, an early exploration of the data revealed that only one person has worked at the company for 37 years. As a result, reidentification may be easier. The record is then dropped from the data to protect this individual's identity. This example uses pandas' `.query()` method, which you can read more about in the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html).\n\n_Note: This technique relates to a larger topic within privacy: K-anonymity. If you want to learn more about it, you can review this [video](https://campus.datacamp.com/courses/data-privacy-and-anonymization-in-python/more-on-privacy-preserving-techniques?ex=7)._","metadata":{},"id":"million-appraisal","cell_type":"markdown"},{"source":"# Specify the query you wish to use here\nquery = \"YearsAtCompany == 37\"\n\n# Create the mask based on your query\nrecord_mask = df.query(query)\n\n# Drop the record(s)\ndf.drop(record_mask.index, inplace=True)\n\n# Run the query to confirm the data is dropped\ndf.query(query)","metadata":{"scrolled":true},"id":"unable-terrorism","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Data Masking\nIf you want to preserve the column but remove all information entirely, you can use data masking. The example below performs data masking on columns with sensitive information, replacing the values with a series of four asterisks (`*`). The new masked columns (named \"columnname_masked\") are previewed next to the original column(s).\n\nFinally, the original columns are dropped so that you are left with only the masked columns.","metadata":{},"id":"satisfactory-tuesday","cell_type":"markdown"},{"source":"# Define columns you want to fully mask\nfull_columns = [\"JobInvolvement\", \"JobSatisfaction\"]\n\n# Define the mask\nfull_mask = \"****\"\n\n# Perform masking on specified columns\nfor col in full_columns:\n    df[col + \"_masked\"] = full_mask\n\n# Preview old and new columns\ndisplay(df[full_columns + [m + \"_masked\" for m in full_columns]])\n\n# Drop original columns\ndf.drop(full_columns, axis=\"columns\", inplace=True)","metadata":{},"id":"loose-latvia","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Partial Data Masking\nAlternatively, you can perform partial data masking. Partial masking involves masking only part of the data. This can help preserve data utility while still maintaining a high level of privacy. In the example below, a new partial mask is applied to the `Zipcode` column by leaving only the first and final characters of the zip code and replacing the remaining characters with an asterisk (`*`).\n\nFor example, 29211 becomes 2\\*\\*\\*1.","metadata":{},"id":"adolescent-fundamental","cell_type":"markdown"},{"source":"# Define the columns you want to partially mask\npartial_columns = [\"Zipcode\"]\n\n# Define the type and number of characters you wish to use as a mask\nmask = \"***\"\n\n# Perform partial masking on specified columns\nfor col in partial_columns:\n    df[col + \"_partially_masked\"] = (\n        df[col].astype(\"string\").apply(lambda s: s[:1] + mask + s[-1])\n    )\n\n# Preview old and new columns\ndisplay(df[partial_columns + [m + \"_partially_masked\" for m in partial_columns]])\n\n# Drop original columns\ndf.drop(partial_columns, axis=\"columns\", inplace=True)","metadata":{},"id":"special-renewal","cell_type":"code","execution_count":null,"outputs":[]},{"source":"You may also want to apply partial masking to email addresses. The code below allows you to specify an email column. It then generates a partially-masked column where the domain name is preserved along with the first letter of the email, but the remaining information is removed.","metadata":{},"id":"valued-decimal","cell_type":"markdown"},{"source":"# Define column containing email information\nemail_column = \"Email\"\n\n# Perform partial masking on the specified column\ndf[email_column + \"_partial_mask\"] = df[email_column].apply(\n    lambda s: s[0] + \"****\" + s[s.find(\"@\") :]\n)\n\n# Preview the old and new column\ndisplay(df[[email_column, str(email_column + \"_partial_mask\")]])\n\n# Drop the original column\ndf.drop(email_column, axis=\"columns\", inplace=True)","metadata":{"scrolled":true},"id":"welsh-clerk","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Data Generalization\nData generalization is used to reduce the precision of data. Generalization has the benefits of maintaining some data usability while still preserving anonymity. \n\nIn the code below, columns are converted into binary values (0 and 1) based on their means. The resulting columns still indicate whether the original value was high or low but obscure the specific details.\n\nAs in other examples, the new generalized columns are previewed next to the original columns, and then the original columns are dropped.","metadata":{},"id":"opened-radio","cell_type":"markdown"},{"source":"# Specify the columns you wish to generalize into binary values\ngeneralization_columns = [\"PerformanceRating\", \"Education\"]\n\n# Perform generalization\nfor col in generalization_columns:\n    col_mean = df[col].mean()\n    df[col + \"_generalized\"] = df[col].apply(lambda x: 0 if x < col_mean else 1)\n\n# Preview old and new columns\ndisplay(\n    df[generalization_columns + [m + \"_generalized\" for m in generalization_columns]]\n)\n\n# Drop original columns\ndf.drop(generalization_columns, axis=\"columns\", inplace=True)","metadata":{},"id":"pretty-corruption","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Alternatively, you can perform top and bottom coding to obscure outliers at a higher risk of identification. Again, this technique helps preserve the utility of the data while granting some anonymity for outliers (e.g., those with very high and very low salaries).\n\nFirst, you can inspect the columns you suspect to have outliers using Seaborn's [`histplot()`](https://seaborn.pydata.org/generated/seaborn.histplot.html) function.","metadata":{},"id":"violent-trigger","cell_type":"markdown"},{"source":"# Specify the columns you wish to inspect\noutlier_columns = [\"MonthlyIncome\", \"Age\"]\n\n# Generate a histogram for each column\nfor col in outlier_columns:\n    sns.histplot(df[col])\n    plt.title(col)\n    plt.show()","metadata":{"scrolled":false},"id":"occupational-testing","cell_type":"code","execution_count":null,"outputs":[]},{"source":"After confirming the distributions of the variables, you can then proceed to top and bottom code the columns by replacing those at the ends of the curves with percentiles. In this example, all values less than or equal to the 5th percentile are recoded as the 5th percentile, and all values greater than or equal to the 95th percentile are recoded to the 95th percentile.\n\nThe same set of histograms is generated to inspect the new distributions, and the old columns are dropped.","metadata":{},"id":"powered-hartford","cell_type":"markdown"},{"source":"# Top and bottom code the 5th and 95th percentiles of each outlier column\nfor col in outlier_columns:\n    lower = df[col].quantile([0.05, 0.95]).iloc[0]\n    upper = df[col].quantile([0.05, 0.95]).iloc[1]\n    df[col + \"_coded\"] = df[col].apply(\n        lambda x: lower if x <= lower else (upper if x >= upper else x)\n    )\n\n# Generate a histogram for each coded column to confirm\nfor col in outlier_columns:\n    sns.histplot(df[col + \"_coded\"])\n    plt.title(col + \"_coded\")\n    plt.show()\n\n# Drop the original columns\ndf.drop(outlier_columns, axis=\"columns\", inplace=True)","metadata":{"scrolled":false},"id":"plain-collectible","cell_type":"code","execution_count":null,"outputs":[]},{"source":"If you want to learn more about anonymity, we highly encourage you to check out [Data Privacy and Anonymization in Python](https://app.datacamp.com/learn/courses/data-privacy-and-anonymization-in-python). This course will introduce you to further techniques for anonymizing data and explore advanced topics such as k-anonymity and differential privacy.","metadata":{},"id":"divine-austria","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6rc1"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":5}