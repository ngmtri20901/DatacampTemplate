{"cells":[{"source":"# Encoding Categorical Variables","metadata":{},"id":"a6fab805","cell_type":"markdown"},{"source":"An important preprocessing step in machine learning is converting categorical variables into a numerical format through encoding. This template will cover how to handle binary and ordered categorical variables with label encoding, as well as one-hot encoding for unordered categorical data.\n\nTo swap in your dataset in this template, the following is required:\n- There must be at least one column with a categorical variable that you want to encode.\n- There must be no NaN/NA values. You can use [this template](https://app.datacamp.com/workspace/templates/recipe-python-impute-missing-data) to impute missing values if needed.\n\nThe placeholder dataset in this template is bank marketing data with details such as job, education, and marital status. Each row represents a different customer. You can find more information on this dataset's source and dictionary [here](https://app.datacamp.com/workspace/datasets/dataset-python-bank-marketing).","metadata":{},"id":"638d1170-c1d6-48be-a2c0-3d7546e340a3","cell_type":"markdown"},{"source":"# Import packages\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n# Load the dataset into a DataFrame\ndf = pd.read_csv(\"bank.csv\")  # Replace with the file you want to use\n\n# Preview the DataFrame\ndf","metadata":{},"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## Label Encoding","metadata":{},"id":"f61aa5b3","cell_type":"markdown"},{"source":"Label encoding is a process where categorical values are replaced by numeric data (i.e., 0, 1, 2, ...). It is appropriate for both binary data and ordinal data (i.e., categorical data that has an inherent order). To label encode categorical data, you can use the [LabelEncoder()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) class from sklearn.\n\n_Note: You can also use [OrdinalEncoder()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder) to perform a similar operation on multiple features._","metadata":{},"id":"c4f39b98-2a60-4940-a81a-8436635a5740","cell_type":"markdown"},{"source":"# Create a copy of the original DataFrame\ndf_encoded = df.copy()\n\n# Specify the column you wish to one-hot encode\nlabel_column = \"education\" \n\n# Initialize the LabelEncoder\nle = LabelEncoder()\n\n# Create a new column using the fit_transform method of the LabelEncoder\ndf_encoded[label_column + \"_enc\"] = le.fit_transform(df_encoded[label_column])\n\n# Preview the original and encoded column\ndf_encoded[[label_column, label_column + \"_enc\"]]","metadata":{},"id":"9ac47884-a3d8-47bf-8975-8c9b70804c1c","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## One-Hot Encoding Using pandas","metadata":{},"id":"1dcbc5b3","cell_type":"markdown"},{"source":"One-hot encoding converts each value in a categorical column into a new column containing 0s and 1s. The simplest way to one-hot encode columns in a DataFrame is to use pandas' [get_dummies()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function, which allows you to specify a subset of the data.\n\nYou simply need to specify the DataFrame that you wish to use. In this example, there are two key arguments:\n- `columns` allows you to choose which columns you wish to be encoded. All columns with an `object` or `category` data type will be encoded if this is not specified. You may sometimes want to avoid this if some categorical columns contain many different values.\n- `drop_first` allows you to return k-1 dummy variables if there are k categories (thus reducing the number of features you create).","metadata":{},"id":"a18490a9-6ec1-4c61-bf97-6c1b371f85e1","cell_type":"markdown"},{"source":"# Specify the columns you wish to one-hot encode\ncategorical_columns = [\n    \"job\",\n    \"marital\"\n]  \n\n# Perform the one-hot encoding\ndf_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n\n# View the resulting DataFrame\ndf_encoded","metadata":{},"id":"b7028896-95e1-4f76-bfbd-264f361765fc","cell_type":"code","execution_count":null,"outputs":[]},{"source":"## One-Hot Encoding Using sklearn","metadata":{},"id":"333d09a7","cell_type":"markdown"},{"source":"You can also use sklearn's [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to one-hot encode categorical columns. While the process is not as simple as it is with pandas, there are key advantages for machine learning. Most importantly, `OneHotEncoder()` can ensure consistency when working with new data. In this example, the encoder is initialized and fit to a subset of the data. The data is then transformed, the column names are retrieved, and it is joined with the original data.\n\nWhile initializing the encoder, the following two arguments are used:\n- `handle_unknown` tells the encoder how to treat unknown categorical features during the transform. If set to \"error\" the encoder will produce an error if it encounters unknown categorical features. If it is set to \"ignore\", the columns for the problematic feature will contain zeros. \n- `sparse` specifies whether a sparse matrix or an array is returned. The code below only works with an array, so `sparse` is set to False.","metadata":{},"id":"9c422a4d-2a79-4bef-a6bb-2052eb31526b","cell_type":"markdown"},{"source":"# Specify the columns you wish to one-hot encode\ncategorical_columns = [\"job\", \"marital\"]\n\n# Filter the DataFrame for the categorical features\ncat_features = df[categorical_columns]\n\n# Initialize the OneHotEncoder and fit it to the categorical features\nenc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\nenc.fit(cat_features)\n\n# Use the transform method to one hot encode the categorical data and then convert it to a DataFrame\nenc_data = pd.DataFrame(\n    enc.transform(cat_features),\n    columns=enc.get_feature_names_out(categorical_columns)\n)\n\n# Join with the rest of the data and preview the DataFrame\ndf_encoded = df.join(enc_data)\ndf_encoded","metadata":{"scrolled":true},"id":"71cfcadc-369c-4a14-ab3f-790ceeb030f3","cell_type":"code","execution_count":null,"outputs":[]},{"source":"Once you have encoded all the categorical variables you want to use, you can remove the original columns and feed the data into a model. If you would like to learn more about preprocessing techniques, be sure to check out the DataCamp course [Preprocessing Data for Machine Learning in Python](https://campus.datacamp.com/courses/preprocessing-for-machine-learning-in-python/introduction-to-data-preprocessing?ex=1).","metadata":{},"id":"46669593","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6rc1"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":5}