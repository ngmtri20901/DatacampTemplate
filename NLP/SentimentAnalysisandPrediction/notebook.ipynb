{"cells":[{"source":"# Sentiment Analysis and Prediction","metadata":{},"id":"mounted-pierce","cell_type":"markdown"},{"source":"Sentiment analysis is the process of understanding the opinion of an author about a subject.\nExamples include analyzing movie ratings, amazon product reviews or the analysis of Twitter tweet sentiment.\n\nFor the purposes of this analysis we will:\n- Explore our data\n- Transform sentiment carrying columns\n- Predict sentiment with a supervised machine learning model","metadata":{},"id":"manual-temperature","cell_type":"markdown"},{"source":"%%capture\n!pip install wordcloud","metadata":{},"id":"concerned-sheep","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Imports\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import (\n    TfidfVectorizer,\n    CountVectorizer,\n)\nfrom wordcloud import WordCloud\nfrom functools import reduce\nfrom nltk import word_tokenize\n\nnltk.download(\"punkt\")","metadata":{},"id":"earned-rwanda","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# 1. Load your data\nUpload data that has textual value and an indication of the sentiment (0 = negative, 1 = positive)","metadata":{},"id":"acknowledged-compiler","cell_type":"markdown"},{"source":"# Upload your data as CSV and load as a data frame\ndf = pd.read_csv('reviews.csv',index_col=0)\ndf","metadata":{},"id":"applied-divorce","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# 2. Word cloud and feature creation\nVisualize words that carry meaning with a word cloud","metadata":{},"id":"fitted-ticket","cell_type":"markdown"},{"source":"positive_df = df[df[\"score\"] == 1][\"review\"][:100]  # 1 = positive, 0 = negative\npositive_df = reduce(lambda a, b: a + b, positive_df)\n\n# Create and generate a word cloud image\ncloud_positives = WordCloud(background_color=\"white\").generate(positive_df)\n\n# Display the generated wordcloud image\nplt.imshow(cloud_positives, interpolation=\"bilinear\")\nplt.title(\"Top 100 positive words\", y=1.02, size=14)  # Choose title, position and size\nplt.axis(\"off\")  # Turn off axis labels\n\n# Don't forget to show the final image\nplt.show()","metadata":{},"id":"medical-lemon","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Tokenize each item in the review column\nword_tokens = [word_tokenize(review) for review in df[\"review\"]]\n\n# Create a new feature for the lengh of each review\ndf[\"n_words\"] = [len(word_tokens[i]) for i in range(len(word_tokens))]\n\ndf","metadata":{},"id":"accurate-today","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# 3. Building a vectorizer\nUse the Tfidf Vectorizer to transform the data into numerical values that can be used to make predictions. ","metadata":{},"id":"complimentary-coral","cell_type":"markdown"},{"source":"# Build the vectorizer\nvect = TfidfVectorizer(\n    stop_words='english',  # Default list of English stop words\n    ngram_range=(1, 2),  # Consider Uni- and Bi-grams\n    max_features=200,  # Max number of features\n    token_pattern=r\"\\b[^\\d\\W][^\\d\\W]+\\b\",  # Capture only words using this pattern\n)  \n\nvect.fit(df.review)\n\n# Create sparse matrix from the vectorizer\nX = vect.transform(df.review)\n\n# Create a DataFrame\ndf_transformed = pd.DataFrame(data=X.toarray(), columns=vect.get_feature_names_out())\ndf_transformed","metadata":{},"id":"modern-merchant","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# 4. Building a classifier\nUse a logistic regression to predict the sentiment of unseen data. \nVisualize the errors your classifier makes with a confusion matrix.","metadata":{},"id":"electronic-struggle","cell_type":"markdown"},{"source":"dropped = df.drop([\"review\", \"n_words\"], axis=1)\ntransformed = pd.concat([dropped, df_transformed], axis=1)\ntransformed","metadata":{},"id":"selected-daisy","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Define X and y\ny = transformed[\"score\"]\nX = transformed.drop(\"score\", axis=1)\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,  # Set size of test_set\n    random_state=456,  # Random seed for reproducibility\n)\n\n# Train a logistic regression\nlog_reg = LogisticRegression().fit(X_train, y_train)\n\n# Predict the labels\ny_predicted = log_reg.predict(X_test)\n\n# Print accuracy score and confusion matrix on test set\nprint(\"Accuracy on the test set: \", accuracy_score(y_test, y_predicted))\nprint(confusion_matrix(y_test, y_predicted) / len(y_test))","metadata":{},"id":"going-triumph","cell_type":"code","execution_count":null,"outputs":[]},{"source":"ConfusionMatrixDisplay.from_estimator(log_reg, X_test, y_test, normalize=\"all\")\nplt.title(\"Confuson Matrix\", y=1.02, size=14)\nplt.show()","metadata":{"scrolled":true},"id":"meaningful-particle","cell_type":"code","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}