{"cells":[{"source":"# Logistic Regression Binary Classification","metadata":{},"id":"e9c78c83-1aec-4d06-b80b-2ab703343c27","cell_type":"markdown"},{"source":"Logistic regression is a fundamental machine learning method originally from the field of statistics. It's a great choice for generating a baseline for any binary classification problem (meaning there are only two outcomes). This template trains and evaluates a logistic regression model for a **binary classification** problem. If you would like to learn more about logistic regression, take a look at DataCamp's [Linear Classifiers in Python](https://app.datacamp.com/learn/courses/linear-classifiers-in-python) course.\n\nTo swap in your dataset in this template, the following is required:\n- There's at least one feature column and a column with a binary categorical target variable you would like to predict.\n- The features have been cleaned and preprocessed, including categorical encoding.\n- There are no NaN/NA values. You can use [this template to impute missing values](https://app.datacamp.com/workspace/templates/recipe-python-impute-missing-data) if needed.\n\nThe placeholder dataset in this template consists of churn data from a telecom company. Each row represents a customer over a year and whether the customer churned (the target variable; `1` = yes, `0` = no). You can find more information on this dataset's source and dictionary [here](https://app.datacamp.com/workspace/datasets/dataset-python-telecom-customer-churn).","metadata":{},"id":"27be9347-9e6f-4811-a1eb-b09638bbb272","cell_type":"markdown"},{"source":"### 1. Loading packages and data","metadata":{},"id":"edf21890","cell_type":"markdown"},{"source":"# Load packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score,\n    confusion_matrix,\n    precision_score,\n    recall_score,\n    RocCurveDisplay,\n)\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the data and replace with your CSV file path\ndf = pd.read_csv(\"data/customer_churn.csv\")\ndf","metadata":{},"id":"336d7477-fda2-4903-9ec9-ef2f75349094","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Check if there are any null values\nprint(df.isnull().sum())","metadata":{},"id":"75a9ce88-e8e5-4544-8bfe-a1429f39552d","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Check columns to make sure you have feature(s) and a target variable\ndf.info()","metadata":{},"id":"e2101794-8fa6-48d7-bc30-33a2cbfb303d","cell_type":"code","execution_count":null,"outputs":[]},{"source":"### 2. Splitting and standardizing the data\nTo split the data, we'll use the [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function. Then, we'll standardize the input data using [`StandardScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) (note: this should be done after splitting the data to avoid data leakage). To learn more about standardizing data and preprocessing techniques, visit DataCamp's [Preprocessing for Machine Learning in Python](https://app.datacamp.com/learn/courses/preprocessing-for-machine-learning-in-python).","metadata":{},"id":"52dd05c0-58b8-4302-aedc-5c76bd73f7b1","cell_type":"markdown"},{"source":"# Split the data into two DataFrames: X (features) and y (target variable)\nX = df.iloc[:, 0:8]  # Specify at least one column as a feature\ny = df[\"Churn\"]  # Specify one column as the target variable\n\n# Split the data into train and test subsets\n# You can adjust the test size and random state\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.30, random_state=123\n)\n\n# Standardize X data based on X_train\nsc = StandardScaler().fit(X_train)\nX_train_scaled = sc.transform(X_train)\nX_test_scaled = sc.transform(X_test)","metadata":{},"id":"913f3de2-d6f1-4b0f-b0b0-a258cc5f430a","cell_type":"code","execution_count":null,"outputs":[]},{"source":"### 3. Building a logistic regression classifier","metadata":{},"id":"cc5abde3-eda6-40b5-bde7-25a6477373da","cell_type":"markdown"},{"source":"The following code builds a scikit-learn logistic regression classifier (`linear_model.LogisticRegression`) using the most fundamental parameters. As a reminder, you can learn more about these parameters in DataCamp's [Linear Classifiers in Python](https://app.datacamp.com/learn/courses/linear-classifiers-in-python) course and [scikit-learn's documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).","metadata":{},"id":"2fca1908-736b-4f0b-9966-a90118863279","cell_type":"markdown"},{"source":"from sklearn import preprocessing\n\n# Define parameters: these will need to be tuned to prevent overfitting and underfitting\nparams = {\n    \"penalty\": \"l2\",  # Norm of the penalty: 'l1', 'l2', 'elasticnet', 'none'\n    \"C\": 1,  # Inverse of regularization strength, a positive float\n    \"random_state\": 123,\n}\n\n# Create a logistic regression classifier object with the parameters above\nclf = LogisticRegression(**params)\n\n# Train the classifer on the train set\nclf = clf.fit(X_train_scaled, y_train)\n\n# Predict the outcomes on the test set\ny_pred = clf.predict(X_test_scaled)","metadata":{},"id":"32af5116-21c3-43cb-aa82-9febfd29dec9","cell_type":"code","execution_count":null,"outputs":[]},{"source":"To evaluate this classifier, we can calculate the accuracy, precision, and recall scores. You'll have to decide which performance metric is best suited for your problem and goal.","metadata":{},"id":"5c9c8d6a","cell_type":"markdown"},{"source":"# Calculate the accuracy, precision, and recall scores\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Precision:\", precision_score(y_test, y_pred))\nprint(\"Recall:\", recall_score(y_test, y_pred))","metadata":{},"id":"e8cd11d7","cell_type":"code","execution_count":null,"outputs":[]},{"source":"### 4. Other evaluation methods: confusion matrix and ROC curve\n\nWe can use a confusion matrix and a receiver operating characteristic (ROC) curve to get a fuller picture of the model's performance. These are available from sklearn's [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) module. ","metadata":{},"id":"21b0f9a2","cell_type":"markdown"},{"source":"# Calculate confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot a labeled confusion matrix with Seaborn\nsns.heatmap(cnf_matrix, annot=True, fmt=\"g\")\nplt.title(\"Confusion matrix\")\nplt.ylabel(\"Actual label\")\nplt.xlabel(\"Predicted label\")","metadata":{},"id":"1de4fdc2","cell_type":"code","execution_count":null,"outputs":[]},{"source":"# Plot ROC curve\nRocCurveDisplay.from_estimator(clf, X_test_scaled, y_test)","metadata":{},"id":"occupied-vegetable","cell_type":"code","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6rc1"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":5}